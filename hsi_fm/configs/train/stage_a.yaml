stage: stage_a
max_steps: 100000
batch_size: 16
optimizer:
  name: adamw
  lr: 3.0e-4
  weight_decay: 0.05
lr_schedule:
  name: cosine
  warmup_steps: 1000
precision: bf16
accumulate_grad_batches: 2
distributed:
  backend: nccl
  use_activation_checkpointing: true
  use_flash_attention: true
